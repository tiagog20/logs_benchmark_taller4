# ğŸ Data Processing Benchmark â€“ Python, Pandas, Polars, DuckDB & Spark

**Autor:** Santiago GonzÃ¡lez Granada  
**Curso:** MinerÃ­a de Grandes VolÃºmenes de Datos â€“ Taller III  
**InstituciÃ³n:** Universidad EAFIT  

---

## ğŸ“˜ DescripciÃ³n General

Este proyecto presenta una **comparativa de rendimiento** entre cinco enfoques de procesamiento de datos a gran escala:

1. **Pure Python (boto3 + json)**
2. **Pandas**
3. **Polars**
4. **DuckDB**
5. **Apache Spark**

El objetivo fue evaluar **tiempo de ejecuciÃ³n**, **uso de CPU** y **consumo de memoria** al procesar volÃºmenes crecientes de datos almacenados en AWS S3, manteniendo un entorno controlado y homogÃ©neo.

---

## âš™ï¸ Entorno Experimental

- **Infraestructura:** AWS EC2 `m5.2xlarge` (8 vCPU, 32 GiB RAM)
- **Sistema Operativo:** Ubuntu 22.04 LTS
- **Dataset:** 25 GB (~50M JSON lines) almacenados en S3
- **Procesamiento:** Lectura y transformaciÃ³n de registros JSON
- **Checkpoints:** mediciones a 5, 10, 15, 20 y 25 GB

---

## â±ï¸ Resultados Globales

| **ImplementaciÃ³n** | **Tiempo total (25 GB)** | **CPU Utilization** | **Memoria MÃ¡x.** | **DescripciÃ³n y Trade-off** |
|:-------------------:|:-------------------------:|:--------------------:|:----------------:|:-----------------------------|
| ğŸ¥‡ **DuckDB** | 8.12 min | Alta | Moderado | ğŸï¸ **El Coche Deportivo:** velocidad pura con excelente eficiencia de recursos. El ganador claro. |
| ğŸ¥ˆ **Polars** | 8.77 min | Alta | Baja | ğŸš— **El Coche de Rally:** casi tan rÃ¡pido como DuckDB, pero con mejor eficiencia de memoria. |
| ğŸ¥‰ **Spark** | 19.6 min | Muy Alta | Muy Alta | ğŸšš **El CamiÃ³n Pesado:** mÃ¡s lento en esta prueba, usa la mayor potencia y memoria. Ideal para escalar mÃ¡s allÃ¡ de 25 GB. |
| 4ï¸âƒ£ **Pure Python** | 26.33 min | Baja | Muy baja | ğŸ›µ **El Scooter ElÃ©ctrico:** el mÃ¡s lento, pero con la huella de recursos mÃ¡s pequeÃ±a. |
| 5ï¸âƒ£ **Pandas** | 35.75 min | Media | Alta | ğŸš™ **El SedÃ¡n Familiar:** cÃ³modo y conocido, pero no apto para grandes volÃºmenes. |

---

## ğŸ” AnÃ¡lisis Resumido

DuckDB logrÃ³ el mejor tiempo de procesamiento total, aprovechando un motor vectorizado en memoria con un paralelismo eficiente.
Polars le siguiÃ³ muy de cerca, mostrando un rendimiento casi idÃ©ntico, con una excelente eficiencia de memoria y ejecuciÃ³n columnar.
Spark proporcionÃ³ un buen rendimiento relativo y una gran escalabilidad distribuida, aunque con una mayor sobrecarga y consumo de recursos.
Pure Python fue significativamente mÃ¡s lento, procesando los datos lÃ­nea por lÃ­nea sin vectorizaciÃ³n ni concurrencia.
Pandas fue el mÃ¡s lento, limitado por la ejecuciÃ³n de un solo subproceso y el alto uso de memoria.

---

## ğŸ§  Conclusiones

- ğŸ¥‡ **DuckDB y Polars** son las opciones mÃ¡s eficientes para procesar grandes volÃºmenes de datos en un solo nodo, combinando **velocidad** y **uso moderado de memoria**.  
- âš™ï¸ **Spark** es mÃ¡s adecuado para **escalabilidad horizontal**, aunque no el mÃ¡s rÃ¡pido en una mÃ¡quina individual.  
- ğŸ **Pandas y Pure Python** sirven como lÃ­nea base o para tareas pequeÃ±as, pero **no son Ã³ptimos** para big data.  

---
