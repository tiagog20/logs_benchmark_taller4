# ğŸ Data Processing Benchmark â€“ Python, Pandas, Polars, DuckDB & Spark

**Autor:** Santiago GonzÃ¡lez Granada  
**Curso:** MinerÃ­a de Grandes VolÃºmenes de Datos â€“ Taller III  
**InstituciÃ³n:** Universidad EAFIT  

---

## ğŸ“˜ DescripciÃ³n General

Este proyecto presenta una **comparativa de rendimiento** entre cinco enfoques de procesamiento de datos a gran escala:

1. **Pure Python (boto3 + json)**
2. **Pandas**
3. **Polars**
4. **DuckDB**
5. **Apache Spark**

El objetivo fue evaluar **tiempo de ejecuciÃ³n**, **uso de CPU** y **consumo de memoria** al procesar volÃºmenes crecientes de datos almacenados en AWS S3, manteniendo un entorno controlado y homogÃ©neo.

---

## âš™ï¸ Entorno Experimental

- **Infraestructura:** AWS EC2 `m5.2xlarge` (8 vCPU, 32 GiB RAM)
- **Sistema Operativo:** Ubuntu 22.04 LTS
- **Dataset:** 25 GB (~50M JSON lines) almacenados en S3
- **Procesamiento:** Lectura y transformaciÃ³n de registros JSON
- **Checkpoints:** mediciones a 5, 10, 15, 20 y 25 GB

---

## â±ï¸ Resultados Globales

| **ImplementaciÃ³n** | **Tiempo total (25 GB)** | **CPU Utilization** | **Memoria MÃ¡x.** | **DescripciÃ³n y Trade-off** |
|:-------------------:|:-------------------------:|:--------------------:|:----------------:|:-----------------------------|
| ğŸ¥‡ **DuckDB** | 8.12 min | Alta | Moderado | ğŸï¸ **El Coche Deportivo:** velocidad pura con excelente eficiencia de recursos. El ganador claro. |
| ğŸ¥ˆ **Polars** | 8.77 min | Alta | Baja | ğŸš— **El Coche de Rally:** casi tan rÃ¡pido como DuckDB, pero con mejor eficiencia de memoria. |
| ğŸ¥‰ **Spark** | 19.6 min | Muy Alta | Muy Alta | ğŸšš **El CamiÃ³n Pesado:** mÃ¡s lento en esta prueba, usa la mayor potencia y memoria. Ideal para escalar mÃ¡s allÃ¡ de 25 GB. |
| 4ï¸âƒ£ **Pure Python** | 26.33 min | Baja | Muy baja | ğŸ›µ **El Scooter ElÃ©ctrico:** el mÃ¡s lento, pero con la huella de recursos mÃ¡s pequeÃ±a. |
| 5ï¸âƒ£ **Pandas** | 35.75 min | Media | Alta | ğŸš™ **El SedÃ¡n Familiar:** cÃ³modo y conocido, pero no apto para grandes volÃºmenes. |

---

## ğŸ” AnÃ¡lisis Resumido

- **DuckDB** achieved the best total processing time, leveraging an **in-memory vectorized engine** with efficient parallelism.  
- **Polars** followed very closely, showing almost identical performance, with excellent **memory efficiency** and **columnar execution**.  
- **Spark** provided good relative performance and strong **distributed scalability**, though with higher overhead and resource consumption.  
- **Pure Python** was significantly slower, processing data **line by line** without vectorization or concurrency.  
- **Pandas** was the **slowest**, limited by **single-threaded execution** and high memory usage.

---

## ğŸ§  Conclusiones

- ğŸ¥‡ **DuckDB y Polars** son las opciones mÃ¡s eficientes para procesar grandes volÃºmenes de datos en un solo nodo, combinando **velocidad** y **uso moderado de memoria**.  
- âš™ï¸ **Spark** es mÃ¡s adecuado para **escalabilidad horizontal**, aunque no el mÃ¡s rÃ¡pido en una mÃ¡quina individual.  
- ğŸ **Pandas y Pure Python** sirven como lÃ­nea base o para tareas pequeÃ±as, pero **no son Ã³ptimos** para big data.  

---

## ğŸ“Š VisualizaciÃ³n Recomendada (Opcional)

Para incluir en reportes o presentaciones:
- Un **grÃ¡fico de barras** con el tiempo total de ejecuciÃ³n (DuckDB y Polars destacan).
- Un **diagrama de trade-offs** mostrando la relaciÃ³n entre velocidad (x), memoria (y) y CPU (tamaÃ±o del punto).

---

## ğŸ“¦ Dependencias (segÃºn implementaciÃ³n)

- **Pure Python:** `boto3`, `json`
- **Pandas:** `pandas`, `boto3`
- **Polars:** `polars`, `boto3`
- **DuckDB:** `duckdb`, `boto3`
- **Spark:** `pyspark`, `boto3`

---